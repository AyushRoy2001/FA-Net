{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Import dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T05:23:01.255315Z","iopub.status.busy":"2024-03-29T05:23:01.254608Z","iopub.status.idle":"2024-03-29T05:23:14.291481Z","shell.execute_reply":"2024-03-29T05:23:14.290559Z","shell.execute_reply.started":"2024-03-29T05:23:01.255286Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Layer\n","import numpy as np\n","import tensorflow.keras as K\n","import tensorflow.keras.backend as Kback"]},{"cell_type":"markdown","metadata":{},"source":["## Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T05:23:14.293571Z","iopub.status.busy":"2024-03-29T05:23:14.293025Z","iopub.status.idle":"2024-03-29T05:23:17.070930Z","shell.execute_reply":"2024-03-29T05:23:17.069968Z","shell.execute_reply.started":"2024-03-29T05:23:14.293542Z"},"trusted":true},"outputs":[],"source":["train_datagen = K.preprocessing.image.ImageDataGenerator(rescale = 1./255, validation_split = 0.2)   \n","\n","train_dataset  = train_datagen.flow_from_directory(directory = 'D:/Dataset by Kermany et al/train',\n","                                                   target_size = (256,256),\n","                                                   class_mode = 'categorical',\n","                                                   subset = 'training',\n","                                                   shuffle=True,\n","                                                   batch_size = 64)\n","validation_dataset  = train_datagen.flow_from_directory(directory = 'D:/Dataset by Kermany et al/train',\n","                                                   target_size = (256,256),\n","                                                   class_mode = 'categorical',\n","                                                   subset = 'validation',\n","                                                   shuffle=True,\n","                                                   batch_size = 64)\n","\n","\n","test_datagen = K.preprocessing.image.ImageDataGenerator(rescale = 1./255)   \n","\n","test_dataset  = test_datagen.flow_from_directory(directory = 'D:/Dataset by Kermany et al/test',\n","                                                   target_size = (256,256),\n","                                                   class_mode = 'categorical',\n","                                                   subset = 'training',\n","                                                   shuffle=False,\n","                                                   batch_size = 64)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T05:23:17.072610Z","iopub.status.busy":"2024-03-29T05:23:17.072252Z","iopub.status.idle":"2024-03-29T05:23:17.078353Z","shell.execute_reply":"2024-03-29T05:23:17.077391Z","shell.execute_reply.started":"2024-03-29T05:23:17.072577Z"},"trusted":true},"outputs":[],"source":["print(train_dataset.class_indices)\n","print(validation_dataset.class_indices)\n","print(test_dataset.class_indices)"]},{"cell_type":"markdown","metadata":{},"source":["## Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T05:23:17.080780Z","iopub.status.busy":"2024-03-29T05:23:17.080507Z","iopub.status.idle":"2024-03-29T05:23:18.296332Z","shell.execute_reply":"2024-03-29T05:23:18.295552Z","shell.execute_reply.started":"2024-03-29T05:23:17.080756Z"},"trusted":true},"outputs":[],"source":["def f1_score(y_true, y_pred):\n","    true_positives = Kback.sum(Kback.round(Kback.clip(y_true * y_pred, 0, 1)))\n","    possible_positives = Kback.sum(Kback.round(Kback.clip(y_true, 0, 1)))\n","    predicted_positives = Kback.sum(Kback.round(Kback.clip(y_pred, 0, 1)))\n","    precision = true_positives / (predicted_positives + Kback.epsilon())\n","    recall = true_positives / (possible_positives + Kback.epsilon())\n","    f1_val = 2*(precision*recall)/(precision+recall+Kback.epsilon())\n","    return f1_val\n","\n","METRICS = [\n","      \"accuracy\",\n","      K.metrics.Precision(name='precision'),\n","      K.metrics.Recall(name='recall'),\n","      K.metrics.AUC(name='auc'),\n","      f1_score\n","]"]},{"cell_type":"markdown","metadata":{},"source":["## Model"]},{"cell_type":"markdown","metadata":{},"source":["#### Custom"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T05:23:18.297746Z","iopub.status.busy":"2024-03-29T05:23:18.297459Z","iopub.status.idle":"2024-03-29T05:23:18.319029Z","shell.execute_reply":"2024-03-29T05:23:18.318159Z","shell.execute_reply.started":"2024-03-29T05:23:18.297721Z"},"trusted":true},"outputs":[],"source":["def SAM_avg(x):\n","    batch, _, _, channel = x.shape\n","    x = K.layers.Conv2D(channel//2, kernel_size=1, padding=\"same\")(x)\n","    x = K.layers.Conv2D(channel//2, kernel_size=3, padding=\"same\")(x)\n","    x = K.layers.BatchNormalization()(x)\n","    x = CAM(x)\n","    ## Average Pooling\n","    x1 = tf.reduce_mean(x, axis=-1)\n","    x1 = tf.expand_dims(x1, axis=-1)\n","    ## Conv layer\n","    feats = K.layers.Conv2D(1, kernel_size=7, padding=\"same\", activation=\"sigmoid\")(x1)\n","    feats = K.layers.Multiply()([x, feats])\n","    return feats\n","\n","def SAM_max(x):\n","    batch, _, _, channel = x.shape\n","    x = K.layers.SeparableConv2D(channel, kernel_size=1, padding=\"same\")(x)\n","    x = K.layers.SeparableConv2D(channel, kernel_size=3, padding=\"same\")(x)\n","    x = K.layers.BatchNormalization()(x)\n","    x = CAM(x)\n","    ## Max Pooling\n","    x2 = tf.reduce_max(x, axis=-1)\n","    x2 = tf.expand_dims(x2, axis=-1)\n","    ## Conv layer\n","    feats = K.layers.Conv2D(1, kernel_size=7, padding=\"same\", activation=\"sigmoid\")(x2)\n","    feats = K.layers.Multiply()([x, feats])\n","    return feats\n","\n","def CSSAM(x):\n","    x_avg = SAM_avg(x)\n","    x_max = SAM_max(x)\n","    x = K.layers.Concatenate()([x_avg, x_max])\n","    x = ChannelDropout(drop_ratio=0.5)(x)\n","    return x\n","\n","def CAM(x, ratio=8):\n","    batch, _, _, channel = x.shape\n","    ## Shared layers\n","    l1 = K.layers.Dense(channel//ratio, activation=\"relu\", use_bias=False)\n","    l2 = K.layers.Dense(channel, use_bias=False)\n","    ## Global Average Pooling\n","    x1 = K.layers.GlobalAveragePooling2D()(x)\n","    x1 = l1(x1)\n","    x1 = l2(x1)\n","    ## Global Max Pooling\n","    x2 = K.layers.GlobalMaxPooling2D()(x)\n","    x2 = l1(x2)\n","    x2 = l2(x2)\n","    ## Add both the features and pass through sigmoid\n","    feats = x1 + x2\n","    feats = K.layers.Activation(\"sigmoid\")(feats)\n","    feats = K.layers.Multiply()([x, feats])\n","    return feats\n","\n","class ChannelDropout(K.layers.Layer):\n","    def __init__(self, drop_ratio=0.2):\n","        super(ChannelDropout, self).__init__()\n","        self.drop_ratio = drop_ratio\n","\n","    def build(self, input_shape):\n","        _, _, _, self.channels = input_shape\n","        # Initialize a trainable mask with ones\n","        self.mask = RichardsSigmoid(units=1)(self.add_weight(\"mask\", shape=(1, 1, 1, self.channels), initializer=\"ones\", trainable=True))\n","\n","    def call(self, x):\n","        # Duplicate the mask to match the batch size\n","        mask = tf.tile(self.mask, [tf.shape(x)[0], 1, 1, 1])\n","        # Multiply the input by the mask\n","        x = x * mask\n","        num_channels_to_keep = int(self.channels // 1.25)\n","        sorted_x, indices = tf.nn.top_k(x, k=num_channels_to_keep, sorted=True)\n","        sorted_x = sorted_x[:,:,:,0:num_channels_to_keep]\n","        return sorted_x\n","    \n","class RichardsSigmoid(K.layers.Layer):\n","    def __init__(self, units=1, **kwargs):\n","        super(RichardsSigmoid, self).__init__(**kwargs)\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        # Initialize learnable parameters: A, Q, mu\n","        self.A = self.add_weight(name='A', shape=(self.units,), initializer='uniform', trainable=True)\n","        self.Q = self.add_weight(name='Q', shape=(self.units,), initializer='uniform', trainable=True)\n","        self.mu = self.add_weight(name='mu', shape=(self.units,), initializer='uniform', trainable=True)\n","\n","        super(RichardsSigmoid, self).build(input_shape)\n","\n","    def call(self, x):\n","        # Richards sigmoid function\n","        return 1 / (1 + tf.exp(-self.A * tf.exp(-self.Q * (x - self.mu))))\n","\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[:-1] + (self.units,)"]},{"cell_type":"markdown","metadata":{},"source":["#### Deep Learner"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T05:23:18.320450Z","iopub.status.busy":"2024-03-29T05:23:18.320200Z","iopub.status.idle":"2024-03-29T05:23:20.882881Z","shell.execute_reply":"2024-03-29T05:23:20.882055Z","shell.execute_reply.started":"2024-03-29T05:23:18.320427Z"},"trusted":true},"outputs":[],"source":["input_layer = K.Input(shape=(256,256,3))\n","\n","deep_learner = K.applications.ResNet50(include_top = False, weights = \"imagenet\", input_tensor = input_layer)\n","for layer in deep_learner.layers:\n","    layer.trainable = True"]},{"cell_type":"markdown","metadata":{},"source":["#### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T05:23:20.884866Z","iopub.status.busy":"2024-03-29T05:23:20.884487Z","iopub.status.idle":"2024-03-29T05:23:22.036811Z","shell.execute_reply":"2024-03-29T05:23:22.035938Z","shell.execute_reply.started":"2024-03-29T05:23:20.884822Z"},"trusted":true},"outputs":[],"source":["input_img = K.layers.Input(shape=(256,256,3)) \n","feat_img = deep_learner(input_img)\n","feat_img = CSSAM(feat_img)\n","flat = K.layers.GlobalAveragePooling2D()(feat_img)\n","output = K.layers.Dense(3, activation='softmax')(flat)\n","\n","model = K.Model(inputs=input_img, outputs=output)\n","optimizer = K.optimizers.Adam(lr=0.0001)\n","model.compile(loss=[\"categorical_crossentropy\"], metrics=METRICS, optimizer = optimizer)\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T05:23:22.038262Z","iopub.status.busy":"2024-03-29T05:23:22.037953Z","iopub.status.idle":"2024-03-29T06:23:23.917964Z","shell.execute_reply":"2024-03-29T06:23:23.917183Z","shell.execute_reply.started":"2024-03-29T05:23:22.038237Z"},"trusted":true},"outputs":[],"source":["model_checkpoint_callback = K.callbacks.ModelCheckpoint(\n","    filepath='saved.h5',\n","    monitor='val_f1_score',\n","    save_best_only=True,\n","    save_weights_only=True,\n","    mode='max',\n","    verbose=1\n","    )\n","\n","history = model.fit(train_dataset,\n","                    epochs = 50,\n","                    validation_data = validation_dataset,\n","                    verbose = 1,\n","                    callbacks=[model_checkpoint_callback],\n","                    shuffle = True)"]},{"cell_type":"markdown","metadata":{},"source":["#### Training plots"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T06:23:23.919531Z","iopub.status.busy":"2024-03-29T06:23:23.919235Z","iopub.status.idle":"2024-03-29T06:23:25.609749Z","shell.execute_reply":"2024-03-29T06:23:25.608781Z","shell.execute_reply.started":"2024-03-29T06:23:23.919504Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def Train_Val_Plot(acc, val_acc, loss, val_loss, auc, val_auc, precision, val_precision, recall, val_recall, f1_score, val_f1_score):\n","    fig, axes = plt.subplots(2, 3, figsize=(20, 10))\n","    fig.suptitle(\"MODEL'S METRICS VISUALIZATION\")\n","\n","    axes[0, 0].plot(range(1, len(acc) + 1), acc)\n","    axes[0, 0].plot(range(1, len(val_acc) + 1), val_acc)\n","    axes[0, 0].set_title('History of Accuracy')\n","    axes[0, 0].set_xlabel('Epochs')\n","    axes[0, 0].set_ylabel('Accuracy')\n","    axes[0, 0].legend(['training', 'validation'])\n","\n","    axes[0, 1].plot(range(1, len(loss) + 1), loss)\n","    axes[0, 1].plot(range(1, len(val_loss) + 1), val_loss)\n","    axes[0, 1].set_title('History of Loss')\n","    axes[0, 1].set_xlabel('Epochs')\n","    axes[0, 1].set_ylabel('Loss')\n","    axes[0, 1].legend(['training', 'validation'])\n","\n","    axes[0, 2].plot(range(1, len(auc) + 1), auc)\n","    axes[0, 2].plot(range(1, len(val_auc) + 1), val_auc)\n","    axes[0, 2].set_title('History of AUC')\n","    axes[0, 2].set_xlabel('Epochs')\n","    axes[0, 2].set_ylabel('AUC')\n","    axes[0, 2].legend(['training', 'validation'])\n","\n","    axes[1, 0].plot(range(1, len(precision) + 1), precision)\n","    axes[1, 0].plot(range(1, len(val_precision) + 1), val_precision)\n","    axes[1, 0].set_title('History of Precision')\n","    axes[1, 0].set_xlabel('Epochs')\n","    axes[1, 0].set_ylabel('Precision')\n","    axes[1, 0].legend(['training', 'validation'])\n","\n","    axes[1, 1].plot(range(1, len(recall) + 1), recall)\n","    axes[1, 1].plot(range(1, len(val_recall) + 1), val_recall)\n","    axes[1, 1].set_title('History of Recall')\n","    axes[1, 1].set_xlabel('Epochs')\n","    axes[1, 1].set_ylabel('Recall')\n","    axes[1, 1].legend(['training', 'validation'])\n","\n","    axes[1, 2].plot(range(1, len(f1_score) + 1), f1_score)\n","    axes[1, 2].plot(range(1, len(val_f1_score) + 1), val_f1_score)\n","    axes[1, 2].set_title('History of F1 score')\n","    axes[1, 2].set_xlabel('Epochs')\n","    axes[1, 2].set_ylabel('Recall')  # Corrected from 'Recall' to 'F1 score'\n","    axes[1, 2].legend(['training', 'validation'])\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Call the function with your history data\n","Train_Val_Plot(history.history['accuracy'], history.history['val_accuracy'],\n","               history.history['loss'], history.history['val_loss'],\n","               history.history['auc'], history.history['val_auc'],\n","               history.history['precision'], history.history['val_precision'],\n","               history.history['recall'], history.history['val_recall'],\n","               history.history['f1_score'], history.history['val_f1_score'])"]},{"cell_type":"markdown","metadata":{},"source":["## Testing"]},{"cell_type":"markdown","metadata":{},"source":["#### Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T06:23:25.612648Z","iopub.status.busy":"2024-03-29T06:23:25.612328Z","iopub.status.idle":"2024-03-29T06:23:40.043562Z","shell.execute_reply":"2024-03-29T06:23:40.042525Z","shell.execute_reply.started":"2024-03-29T06:23:25.612621Z"},"trusted":true},"outputs":[],"source":["model.load_weights(\"saved.h5\")\n","loss, accuracy, precision, recall, auc, f1_score = model.evaluate(test_dataset)\n","print(\"Accuracy\", accuracy)\n","print(\"Loss\", loss)\n","print(\"Precision\", precision)\n","print(\"Recall\", recall)\n","print(\"AUC\", auc)\n","print(\"F1-score\", f1_score)"]},{"cell_type":"markdown","metadata":{},"source":["#### Confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T06:23:40.045032Z","iopub.status.busy":"2024-03-29T06:23:40.044731Z","iopub.status.idle":"2024-03-29T06:23:49.716129Z","shell.execute_reply":"2024-03-29T06:23:49.715197Z","shell.execute_reply.started":"2024-03-29T06:23:40.045004Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n","Y_pred = model.predict_generator(test_dataset, 1157)\n","y_pred = np.argmax(Y_pred, axis=1)\n","print('Confusion Matrix')\n","disp = ConfusionMatrixDisplay(confusion_matrix(test_dataset.classes, y_pred),display_labels=['N', 'PB', 'PV'])\n","disp.plot()\n","plt.show()\n","print('Classification Report')\n","target_names = ['N', 'PB', 'PV']\n","print(classification_report(test_dataset.classes, y_pred, target_names=target_names))"]},{"cell_type":"markdown","metadata":{},"source":["#### Feature subspace"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T06:23:49.717644Z","iopub.status.busy":"2024-03-29T06:23:49.717344Z","iopub.status.idle":"2024-03-29T06:33:12.230480Z","shell.execute_reply":"2024-03-29T06:33:12.229630Z","shell.execute_reply.started":"2024-03-29T06:23:49.717616Z"},"trusted":true},"outputs":[],"source":["modeller = K.Model(inputs=model.input, outputs=model.get_layer(name=\"global_average_pooling2d\").output)\n","# Define the number of classes\n","num_classes = 3\n","\n","# Initialize empty arrays for features and labels\n","all_features = []\n","all_labels = []\n","\n","max_iterations = 624\n","i=0\n","\n","# Extract features and labels from the Keras test generator\n","for batch_features, batch_labels in test_dataset:\n","    features = modeller.predict(batch_features)\n","    all_features.append(features)\n","    all_labels.append(batch_labels)\n","    i+=1\n","    if i >= max_iterations - 1:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-29T06:33:12.232080Z","iopub.status.busy":"2024-03-29T06:33:12.231731Z","iopub.status.idle":"2024-03-29T06:33:35.100162Z","shell.execute_reply":"2024-03-29T06:33:35.098914Z","shell.execute_reply.started":"2024-03-29T06:33:12.232032Z"},"trusted":true},"outputs":[],"source":["from sklearn.decomposition import PCA\n","import matplotlib.pyplot as plt\n","j_range = range(624)  # Adjust the range as needed\n","\n","fig = plt.figure(figsize=(6, 6))\n","ax = fig.add_subplot(111, projection='3d')\n","\n","# Define colors for different classes\n","colors = ['y', 'r', 'g']\n","\n","# Set the size and alpha for the points\n","point_size = 40\n","point_alpha = 0.3\n","\n","for j in j_range:\n","    # Check if the number of samples or features is less than 3\n","#     if all_features[j].shape[0] < 3 or all_features[j].shape[1] < 3:\n","#         continue\n","    \n","    # Apply PCA to reduce the dimension to 3\n","    pca = PCA(n_components=3)\n","    \n","    features_pca_0 = pca.fit_transform(all_features[j])\n","\n","    # Get the labels for this 'j'\n","    labels = all_labels[j]\n","\n","    # Plot each class with circular markers and different colors\n","    for i in range(num_classes):\n","        class_indices = np.where(labels[:, i] == 1)[0]\n","        current_color = colors[i % len(colors)]  # Get the color for this class\n","        ax.scatter(features_pca_0[class_indices, 0], features_pca_0[class_indices, 1], features_pca_0[class_indices, 2], c=current_color, marker='o', s=point_size, alpha=point_alpha, ec='black')\n","\n","ax.set_xlabel('X-axis')\n","ax.set_ylabel('Y-axis')\n","ax.set_zlabel('Z-axis')\n","\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":3992927,"sourceId":6952118,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
